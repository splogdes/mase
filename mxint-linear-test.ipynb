{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.nn.quantized.functional import linearMXInt\n",
    "import torch\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "set_logging_verbosity(\"debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7745, 0.4369, 0.5191, 0.6159, 0.8102, 0.9801, 0.1147, 0.3168],\n",
      "        [0.6965, 0.9143, 0.9351, 0.9412, 0.5995, 0.0652, 0.5460, 0.1872],\n",
      "        [0.0340, 0.9442, 0.8802, 0.0012, 0.5936, 0.4158, 0.4177, 0.2711],\n",
      "        [0.6923, 0.2038, 0.6833, 0.7529, 0.8579, 0.6870, 0.0051, 0.1757]])\n",
      "tensor([0.7497, 0.6047, 0.1100, 0.2121])\n",
      "\n",
      "tensor([[[2.8045, 2.5164, 1.8172, 1.7331],\n",
      "         [2.1832, 2.4806, 1.3740, 1.4209],\n",
      "         [3.6595, 3.0752, 2.2102, 2.5467],\n",
      "         [2.6786, 2.8069, 2.1306, 1.8768],\n",
      "         [2.4971, 1.8619, 1.5163, 1.4707],\n",
      "         [2.2756, 2.4578, 1.6089, 1.4782],\n",
      "         [3.4909, 3.8820, 2.3495, 2.8353],\n",
      "         [2.9913, 2.1998, 1.3497, 2.1574]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "width, exp_width, parallel = 8,3, [1,2]\n",
    "\n",
    "quant_config = {\n",
    "    \"weight_width\": width,\n",
    "    \"weight_exponent_width\": exp_width,\n",
    "    \"weight_block_size\": parallel,\n",
    "    \"bias_width\": width,\n",
    "    \"bias_exponent_width\": exp_width,\n",
    "    \"bias_block_size\": parallel,\n",
    "    \"data_in_width\": width,\n",
    "    \"data_in_exponent_width\": exp_width,\n",
    "    \"data_in_block_size\": parallel\n",
    "}\n",
    "\n",
    "x = torch.rand([1,8,8])\n",
    "weight = torch.rand([4,8])\n",
    "bias = torch.rand([4])\n",
    "\n",
    "print(weight)\n",
    "print(bias)\n",
    "print()\n",
    "\n",
    "y = linearMXInt(x,weight,bias=bias, config=quant_config)\n",
    "\n",
    "print(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from chop.nn.quantized.modules.linear import LinearMXInt\n",
    "\n",
    "layer = torch.nn.Linear(8,4)\n",
    "layer.weight = torch.nn.Parameter(weight)\n",
    "layer.bias = torch.nn.Parameter(bias)\n",
    "\n",
    "kwargs = {\n",
    "    \"in_features\": layer.in_features,\n",
    "    \"out_features\": layer.out_features,\n",
    "    \"config\": quant_config\n",
    "}\n",
    "\n",
    "new_layer = LinearMXInt(**kwargs)\n",
    "new_layer.weight = layer.weight\n",
    "new_layer.bias = layer.bias\n",
    "\n",
    "print(new_layer.forward(x) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph.transforms import quantize_transform_pass\n",
    "from chop.passes.graph.analysis import report_node_type_analysis_pass, init_metadata_analysis_pass, add_common_metadata_analysis_pass\n",
    "from chop.ir.graph.mase_graph import MaseGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Toy FC model for digit recognition on MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(8, 4, bias=True)\n",
    "        self.fc1.weight.data = weight\n",
    "        self.fc1.bias.data = bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %fc1 : [num_users=1] = call_module[target=fc1](args = (%x,), kwargs = {})\n",
      "    return fc1\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_node_type_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Node name    Fx Node op    Mase type            Mase op      Value type\n",
      "-----------  ------------  -------------------  -----------  ------------\n",
      "x            placeholder   placeholder          placeholder  NA\n",
      "fc1          call_module   module_related_func  linear       mxint\n",
      "output       output        output               output       NA\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mg = MaseGraph(model=mlp)\n",
    "\n",
    "\n",
    "dummy_in = {\"x\": torch.randn((1, 8, 8))}\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "mg, _ = add_common_metadata_analysis_pass(\n",
    "    mg, {\"dummy_in\": dummy_in, \"add_value\": False}\n",
    ")\n",
    "\n",
    "quan_args = {\n",
    "    'by': 'type',\n",
    "    'report': True,\n",
    "    'default': \n",
    "    {\n",
    "        'config': quant_config\n",
    "    }\n",
    "}\n",
    "quan_args['default']['config']['name'] = 'mxint'\n",
    "\n",
    "mg, _ = quantize_transform_pass(mg, quan_args)\n",
    "\n",
    "_ = report_node_type_analysis_pass(mg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.8076, 2.5207, 1.8242, 1.7314],\n",
      "         [2.1888, 2.4864, 1.3769, 1.4250],\n",
      "         [3.6686, 3.0870, 2.2192, 2.5497],\n",
      "         [2.6791, 2.8037, 2.1303, 1.8741],\n",
      "         [2.4995, 1.8638, 1.5168, 1.4671],\n",
      "         [2.2822, 2.4645, 1.6113, 1.4794],\n",
      "         [3.4983, 3.8944, 2.3525, 2.8433],\n",
      "         [2.9918, 2.2058, 1.3558, 2.1525]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[2.8045, 2.5164, 1.8172, 1.7331],\n",
      "         [2.1832, 2.4806, 1.3740, 1.4209],\n",
      "         [3.6595, 3.0752, 2.2102, 2.5467],\n",
      "         [2.6786, 2.8069, 2.1306, 1.8768],\n",
      "         [2.4971, 1.8619, 1.5163, 1.4707],\n",
      "         [2.2756, 2.4578, 1.6089, 1.4782],\n",
      "         [3.4909, 3.8820, 2.3495, 2.8353],\n",
      "         [2.9913, 2.1998, 1.3497, 2.1574]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0030, -0.0043, -0.0070,  0.0017],\n",
      "         [-0.0057, -0.0057, -0.0029, -0.0041],\n",
      "         [-0.0091, -0.0118, -0.0090, -0.0031],\n",
      "         [-0.0006,  0.0032,  0.0003,  0.0027],\n",
      "         [-0.0024, -0.0019, -0.0005,  0.0036],\n",
      "         [-0.0066, -0.0067, -0.0023, -0.0012],\n",
      "         [-0.0074, -0.0124, -0.0029, -0.0080],\n",
      "         [-0.0005, -0.0060, -0.0061,  0.0049]]], grad_fn=<SubBackward0>)\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(mlp.forward(x))\n",
    "print(mg.model.forward(x))\n",
    "\n",
    "\n",
    "\n",
    "print(mg.model.forward(x) - mlp.forward(x))\n",
    "print(mg.model.forward(x) - y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
